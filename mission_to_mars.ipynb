{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\ayoat001\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\ayoat001\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from selenium) (1.25.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mission To Mars Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - NASA Mars News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the [NASA Mars News Site](https://mars.nasa.gov/news/) and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import librariesdriver = webdrive\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring elements for grabbing\n",
    "article_header = 'slide'\n",
    "content_title = 'content_title'\n",
    "content_body = 'article_teaser_body'\n",
    "wait_element = 'news'\n",
    "mars_news_url = \"https://mars.nasa.gov/news/\"\n",
    "\n",
    "driver = webdriver.Chrome('C:/Users/ayoat001/Desktop/USC-LA-DATA-PT-11-2019-U-C/11-Web-Scraping-and-Document-Databases/Homework/chromedriver.exe')\n",
    "#get url and wait until the page is fully loaded before proceeding\n",
    "driver.get(mars_news_url)    \n",
    "try:\n",
    "    element = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID,wait_element))\n",
    "    )\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return a list of divs that hold the articles\n",
    "articles = driver.find_elements_by_class_name(article_header)\n",
    "articles[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print first article title and preview paragraph\n",
    "print(articles[0].find_element_by_class_name(content_title).text)\n",
    "print(articles[0].find_element_by_class_name(content_title).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - JPL Mars Space Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_image_url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "featured_image_response = requests.get(featured_image_url)\n",
    "\n",
    "if featured_image_response.status_code == 200:\n",
    "    featured_image_html = featured_image_response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_image_soup = BeautifulSoup(featured_image_html, \"html.parser\")\n",
    "image_element = featured_image_soup.findAll(\"a\", {\"class\": \"button fancy\"}).get('data-fancybox-href')\n",
    "    \n",
    "featured_image_url = \"https://www.jpl.nasa.gov\" + image_element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Mars Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tweets_url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "driver = webdriver.Chrome('C:/Users/ayoat001/Desktop/USC-LA-DATA-PT-11-2019-U-C/11-Web-Scraping-and-Document-Databases/Homework/chromedriver.exe')\n",
    "driver.get(weather_tweets_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get using Xpath\n",
    "mars_weather = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/main/div/div/div/div/div/div/div/div/div[2]/section/div/div/div/div[1]/div/div/div/article/div/div[2]/div[2]/div[2]/div[1]/div/span\")\n",
    "   \n",
    "weather_tweet = mars_weather.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_fact_url = \"https://space-facts.com/mars/\"\n",
    "all_mars_fact_tables = pd.read_html(mars_fact_url)\n",
    "df_mars_facts = all_mars_fact_tables[0]\n",
    "df_mars_facts.columns = [\"Measure\", \"Number\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 - Mars Hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_hemisphere_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "mars_hemisphere_response = requests.get(mars_hemisphere_url)\n",
    "\n",
    "if mars_hemisphere_response.status_code == 200:\n",
    "    mars_hemisphere_html = mars_hemisphere_response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_hemisphere_soup = BeautifulSoup(mars_hemisphere_html, \"html.parser\")\n",
    "    link_elements = mars_hemisphere_soup.findAll(\"a\", {\"class\": \"itemLink product-item\"})\n",
    "    full_page_links = [dict(title=get_full_image_link(\"https://astrogeology.usgs.gov\" + le.get('href'))[0], img_url=get_full_image_link(\"https://astrogeology.usgs.gov\" + le.get('href'))[1]) for le in link_elements]\n",
    "\n",
    "    return dict(first_article_headline=first_article_headline,\n",
    "    first_article_paragraph = first_article_paragraph,\n",
    "    featured_image_url=featured_image_url,\n",
    "    weather_tweet=weather_tweet,\n",
    "    df_mars_facts=df_mars_facts.to_dict(\"records\"),\n",
    "    full_page_links=full_page_links\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(scrape())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_full_image_link(link):\n",
    "\n",
    "        response = requests.get(link)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            html = response.text\n",
    "        \n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        \n",
    "        img_link = soup.find(\"a\", text=\"Original\").get(\"href\")\n",
    "        title = soup.find(\"h2\", class_=\"title\").text.split(\" Enhanced\")[0]\n",
    "            \n",
    "        return [title, img_link]b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    return dict(first_article_headline=first_article_headline,\n",
    "    first_article_paragraph = first_article_paragraph,\n",
    "    featured_image_url=featured_image_url,\n",
    "    weather_tweet=weather_tweet,\n",
    "    df_mars_facts=df_mars_facts.to_dict(\"records\"),\n",
    "    full_page_links=full_page_links\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(scrape())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
